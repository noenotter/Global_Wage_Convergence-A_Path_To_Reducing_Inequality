{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "25ede4b2-7c52-43b5-bd65-715627512008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Merged file saved to: ../Result/Merged_single_column_hours_cleaned_TEST.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Optional helper (reuse across notebooks)\n",
    "def get_path(*parts):\n",
    "    return os.path.join('..', *parts)\n",
    "\n",
    "\n",
    "# --- 1. Load both CSV files and set \"Country\" as index ---\n",
    "df_hours1 = pd.read_csv(get_path('Data', 'Working_hours_Penn.csv'))\n",
    "df_hours2 = pd.read_csv(get_path('Data', 'Working_hours_annualy_average.csv'))\n",
    "\n",
    "df_hours1.set_index(\"Country\", inplace=True)\n",
    "df_hours2.set_index(\"Country\", inplace=True)\n",
    "\n",
    "\n",
    "# 2. Merge the dataframes on Country using an outer join\n",
    "#    We'll give the second dataframe's columns a suffix \"_penn\"\n",
    "df_merged = df_hours1.join(df_hours2, how=\"outer\", lsuffix=\"\", rsuffix=\"_penn\")\n",
    "\n",
    "# 3. Combine each pair of year columns into a single column\n",
    "#    (fill missing from df_hours1 with df_hours2, then drop the second column)\n",
    "years = range(1990, 2026)  # adjust if needed\n",
    "for y in years:\n",
    "    col_a = str(y)             # e.g. \"1990\"\n",
    "    col_b = f\"{y}_penn\"        # e.g. \"1990_penn\"\n",
    "    \n",
    "    if col_a in df_merged.columns and col_b in df_merged.columns:\n",
    "        # Fill missing from col_a with col_b\n",
    "        df_merged[col_a] = df_merged[col_a].fillna(df_merged[col_b])\n",
    "        df_merged.drop(columns=[col_b], inplace=True)\n",
    "    elif col_b in df_merged.columns:\n",
    "        # If col_a doesn't exist, rename col_b -> col_a\n",
    "        df_merged.rename(columns={col_b: col_a}, inplace=True)\n",
    "\n",
    "# 4. Sort alphabetically by \"Country\" (the index), then reset the index\n",
    "df_merged.sort_index(inplace=True)\n",
    "df_merged.reset_index(inplace=True)\n",
    "\n",
    "# 5. Clean up \"~\" and round numeric columns\n",
    "columns_to_clean = [col for col in df_merged.columns if col != \"Country\"]\n",
    "for col in columns_to_clean:\n",
    "    # Convert to string to remove \"~\" and handle 'nan'\n",
    "    df_merged[col] = (df_merged[col].astype(str)\n",
    "                                 .str.replace('~', '')  # remove tilde\n",
    "                                 .replace('nan', '')    # handle 'nan' strings\n",
    "                     )\n",
    "    # Convert to numeric (float), coercing errors to NaN\n",
    "    df_merged[col] = pd.to_numeric(df_merged[col], errors='coerce')\n",
    "    # Round to nearest whole number\n",
    "    df_merged[col] = df_merged[col].round(0)\n",
    "    # Convert to an integer type (nullable Int64 if you want to keep NaN)\n",
    "    df_merged[col] = df_merged[col].astype('Int64')\n",
    "\n",
    "# 6. Save the merged, cleaned file to a single CSV\n",
    "df_merged.to_csv(\"merged_single_column_hours_cleaned.csv\", index=False)\n",
    "output_path = get_path('Result', 'Merged_single_column_hours_cleaned_TEST.csv')\n",
    "df_merged.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"✅ Merged file saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "11d9fbf6-ffda-49eb-bb9d-ec5c1a34c65a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 69 countries in common.\n",
      "✅ Saved common countries to: ../Result/common_countries.txt\n",
      "Saved comparison plots for 69 countries to ../Result/Plots/Hours_Comparison_by_Country.pdf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "# Paths to the two datasets\n",
    "penn_path   = get_path('Data', 'Working_hours_Penn.csv')\n",
    "merged_path = get_path('Result', 'Merged_single_column_hours_cleaned_TEST.csv')\n",
    "\n",
    "\n",
    "# 1. Load original Penn hours and merged cleaned hours\n",
    "df_penn   = pd.read_csv(penn_path)\n",
    "df_merged = pd.read_csv(merged_path)\n",
    "\n",
    "# 2. Normalize country column name and year columns to numeric\n",
    "df_penn.columns = df_penn.columns.str.strip().str.lower()\n",
    "df_merged.columns = df_merged.columns.str.strip().str.lower()\n",
    "\n",
    "# Melt Penn (if still wide) to long form\n",
    "if 'year' not in df_penn.columns:\n",
    "    df_penn = df_penn.melt(id_vars=['country'], var_name='year', value_name='hours_penn')\n",
    "df_penn['year'] = pd.to_numeric(df_penn['year'], errors='coerce')\n",
    "\n",
    "# Melt merged (if still wide) to long form\n",
    "if 'year' not in df_merged.columns:\n",
    "    df_merged = df_merged.melt(id_vars=['country'], var_name='year', value_name='hours_merged')\n",
    "df_merged['year'] = pd.to_numeric(df_merged['year'], errors='coerce')\n",
    "\n",
    "# 3. Identify countries in common\n",
    "common_countries = sorted(set(df_penn['country']).intersection(df_merged['country']))\n",
    "print(f\"Found {len(common_countries)} countries in common.\")\n",
    "\n",
    "# A: as a plain text file, one country per line\n",
    "# Save common countries list\n",
    "txt_path = get_path('Result', 'common_countries.txt')\n",
    "with open(txt_path, 'w') as f:\n",
    "    for c in common_countries:\n",
    "        f.write(c + '\\n')\n",
    "\n",
    "print(f\"✅ Saved common countries to: {txt_path}\")\n",
    "\n",
    "# 4. Create a multi-page PDF to save one plot per country\n",
    "output_pdf = get_path('Result', 'Plots', 'Hours_Comparison_by_Country.pdf')\n",
    "with PdfPages(output_pdf) as pdf:\n",
    "    for country in common_countries:\n",
    "        # filter data\n",
    "        d1 = df_penn[df_penn['country'] == country].sort_values('year')\n",
    "        d2 = df_merged[df_merged['country'] == country].sort_values('year')\n",
    "\n",
    "        # skip if no data\n",
    "        if d1.empty or d2.empty:\n",
    "            continue\n",
    "\n",
    "        # Plot\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.plot(d1['year'], d1['hours_penn'],   marker='o', label='Penn Hours')\n",
    "        plt.plot(d2['year'], d2['hours_merged'], marker='x', label='Merged Hours')\n",
    "        plt.title(f'Working Hours Comparison: {country}')\n",
    "        plt.xlabel('Year')\n",
    "        plt.ylabel('Annual Hours Worked')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        pdf.savefig()\n",
    "        plt.close()\n",
    "\n",
    "print(f\"Saved comparison plots for {len(common_countries)} countries to {output_pdf}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e2909de7-50ca-484e-8074-1de41efe8613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Extrapolated hours for selected countries saved to: ../Result/Hours_extrapolated_1990_2023_selected.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pj/s_kq924572g7znglnlstjmn40000gn/T/ipykernel_52871/2271354249.py:58: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filled = df_long.groupby('Country', group_keys=False).apply(process_country)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# List of countries to apply trend extrapolation\n",
    "countries_to_modify = [\n",
    "    \"Argentina\", \"Australia\", \"Austria\", \"Bangladesh\", \"Belgium\", \"Brazil\",\n",
    "    \"Bulgaria\", \"Cambodia\", \"Canada\", \"Chile\", \"China\", \"China, Hong Kong SAR\",\n",
    "    \"Colombia\", \"Costa Rica\", \"Croatia\", \"Cyprus\", \"Czech Republic\", \"Denmark\",\n",
    "    \"Dominican Republic\", \"Ecuador\", \"Estonia\", \"Finland\", \"France\", \"Germany\",\n",
    "    \"Greece\", \"Hungary\", \"Iceland\", \"India\", \"Indonesia\", \"Ireland\", \"Israel\",\n",
    "    \"Italy\", \"Jamaica\", \"Japan\", \"Latvia\", \"Lithuania\", \"Luxembourg\", \"Malaysia\",\n",
    "    \"Malta\", \"Mexico\", \"Myanmar\", \"Netherlands\", \"New Zealand\", \"Norway\",\n",
    "    \"Pakistan\", \"Peru\", \"Philippines\", \"Poland\", \"Portugal\", \"Republic of Korea\",\n",
    "    \"Romania\", \"Russian Federation\", \"Singapore\", \"Slovakia\", \"Slovenia\",\n",
    "    \"South Africa\", \"Spain\", \"Sri Lanka\", \"Sweden\", \"Switzerland\", \"Taiwan\",\n",
    "    \"Thailand\", \"Trinidad and Tobago\", \"Turkey\", \"United Kingdom\", \"United States\",\n",
    "    \"Uruguay\", \"Venezuela (Bolivarian Republic of)\", \"Viet Nam\"\n",
    "]\n",
    "\n",
    "# 1) Load the merged\n",
    "# ✅ Define the correct path to your merged file\n",
    "path = get_path('Result', 'Merged_single_column_hours_cleaned_TEST.csv')\n",
    "df_wide = pd.read_csv(path)\n",
    "\n",
    "# 2) Melt to long form: Country, year, hours\n",
    "df_long = df_wide.melt(id_vars='Country', var_name='year', value_name='hours')\n",
    "df_long['year'] = pd.to_numeric(df_long['year'], errors='coerce')\n",
    "\n",
    "# 3) For each country in the list, fit a regression on years ≤2019 and predict 2020–2023\n",
    "global_cutoff = 2019\n",
    "def fill_with_trend(g):\n",
    "    train = g[(g['year'] <= global_cutoff) & g['hours'].notna()]\n",
    "    if len(train) < 2:\n",
    "        return g\n",
    "    X = train[['year']].values\n",
    "    y = train['hours'].values\n",
    "    model = LinearRegression().fit(X, y)\n",
    "    future_years = np.arange(global_cutoff + 1, 2024)\n",
    "    Xf = future_years.reshape(-1, 1)\n",
    "    yf = model.predict(Xf)\n",
    "    df_pred = pd.DataFrame({\n",
    "        'Country': g.name,\n",
    "        'year': future_years,\n",
    "        'hours': yf\n",
    "    })\n",
    "    hist = g[g['year'] <= global_cutoff]\n",
    "    return pd.concat([hist, df_pred], ignore_index=True)\n",
    "\n",
    "def process_country(g):\n",
    "    if g.name in countries_to_modify:\n",
    "        return fill_with_trend(g)\n",
    "    else:\n",
    "        return g\n",
    "\n",
    "# Apply only to selected countries\n",
    "df_filled = df_long.groupby('Country', group_keys=False).apply(process_country)\n",
    "\n",
    "# 4) Pivot back to wide form\n",
    "df_corrected = df_filled.pivot(index='Country', columns='year', values='hours').reset_index()\n",
    "\n",
    "# 5) Round to nearest integer\n",
    "years = [c for c in df_corrected.columns if isinstance(c, (int, float))]\n",
    "df_corrected[years] = df_corrected[years].round(0).astype('Int64')\n",
    "\n",
    "# 6)Save corrected CSV\n",
    "out_path = get_path('Result', 'Hours_extrapolated_1990_2023_selected.csv')\n",
    "df_corrected.to_csv(out_path, index=False)\n",
    "\n",
    "print(f\"✅ Extrapolated hours for selected countries saved to: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "34e387b9-d148-4db6-a684-f4c05638014d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved updated comparison plots to:\n",
      "  ../Result/Plots/Hours_Comparison_Old_vs_Extrapolated.pdf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "# paths\n",
    "old_path = get_path('Result', 'Merged_single_column_hours_cleaned_TEST.csv')\n",
    "new_path = get_path('Result', 'Hours_extrapolated_1990_2023_selected.csv')\n",
    "\n",
    "# 1) load and melt old vs new\n",
    "df_old = pd.read_csv(old_path).melt(\n",
    "    id_vars='Country', var_name='year', value_name='old_hours'\n",
    ")\n",
    "df_old['year'] = pd.to_numeric(df_old['year'], errors='coerce')\n",
    "\n",
    "df_new = pd.read_csv(new_path).melt(\n",
    "    id_vars='Country', var_name='year', value_name='new_hours'\n",
    ")\n",
    "df_new['year'] = pd.to_numeric(df_new['year'], errors='coerce')\n",
    "\n",
    "# 2) restrict to common Country×year pairs\n",
    "df_cmp = (\n",
    "    df_old.merge(df_new, on=['Country','year'], how='inner')\n",
    "    .sort_values(['Country','year'])\n",
    ")\n",
    "\n",
    "# 3) plot each country into a multipage PDF\n",
    "out_pdf = get_path('Result','Plots', 'Hours_Comparison_Old_vs_Extrapolated.pdf')\n",
    "with PdfPages(out_pdf) as pdf:\n",
    "    for country, grp in df_cmp.groupby('Country'):\n",
    "        plt.figure(figsize=(8,4))\n",
    "        plt.plot(grp['year'], grp['old_hours'], marker='o', label='Old (raw/merged)')\n",
    "        plt.plot(grp['year'], grp['new_hours'], marker='x', label='New (extrapolated)')\n",
    "        plt.title(f'Hours Worked Comparison: {country}')\n",
    "        plt.xlabel('Year')\n",
    "        plt.ylabel('Annual Hours Worked')\n",
    "        plt.legend()\n",
    "        plt.grid(True, linestyle='--', alpha=0.6)\n",
    "        plt.tight_layout()\n",
    "        pdf.savefig()\n",
    "        plt.close()\n",
    "\n",
    "print(f\"Saved updated comparison plots to:\\n  {out_pdf}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
